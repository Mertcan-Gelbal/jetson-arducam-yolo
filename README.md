# Jetson Arducam AI Kit

A flexible, production-ready environment for running modern Computer Vision models (YOLOv8, YOLOv11, RT-DETR, EfficientNet, etc.) with Arducam hardware on NVIDIA Jetson.

## ğŸš€ Features

*   **Universal Model Support:** Run any model supported by Ultralytics and PyTorch (Object Detection, Segmentation, Pose Estimation, Classification).
*   **Dynamic Platform:** Automatically adapts to JetPack 5.x or 6.x.
*   **Dual Camera Support:** Full support for both **CSI/MIPI** (Arducam IMX series) and **USB Webcams** (Logitech, Intel Realsense).
*   **Hardware Acceleration:** Optimized GStreamer pipelines for CSI and V4L2 for USB.
*   **TensorRT Ready:** Tools to convert any supported model to TensorRT.

## ğŸ“‚ Project Structure

```text
jetson-arducam-ai/
â”œâ”€â”€ Dockerfile                  # Generic AI environment (PyTorch + Ultralytics)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_docker.sh         # Builds 'jetson-arducam' image
â”‚   â”œâ”€â”€ run_docker.sh           # Runs 'jetson-arducam-ctr' container
â”‚   â”œâ”€â”€ setup_cameras.sh        # Universal camera driver installer
â”‚   â””â”€â”€ test_installation.sh    # System diagnostics
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_detection.py      # Inference demo (supports all YOLO versions)
â”‚   â”œâ”€â”€ multi_camera_detection.py # Multi-stream threading example
â”‚   â”œâ”€â”€ gstreamer_pipeline.py   # Low-latency ISP pipeline
â”‚   â””â”€â”€ tensorrt_export.py      # Model optimizer
â””â”€â”€ docs/                       # Guides for Installation, Usage & Troubleshooting
```

## ğŸ› ï¸ Installation

### Automated Setup (Recommended)
The master installer orchestrates driver verification, system checks, and Docker builds.

```bash
git clone https://github.com/Mertcan-Gelbal/jetson-arducam-yolo.git
cd jetson-arducam-yolo
./install.sh
```

### Manual Individual Steps
If you prefer manual control:
1.  **Drivers:** `./scripts/setup_cameras.sh`
2.  **Verify:** `./scripts/test_installation.sh`
3.  **Build:** `./scripts/build_docker.sh`
4.  **Run:** `./scripts/run_docker.sh`

## ğŸ§  Usage

The environment supports the entire Ultralytics ecosystem. You can swap models easily.

### Running Different Models

```bash
# Enter container
sudo docker exec -it jetson-arducam-ctr bash

# YOLOv8 Nano (Fastest)
python3 examples/basic_detection.py --model yolov8n.pt

# YOLOv8 Medium (Better Accuracy)
python3 examples/basic_detection.py --model yolov8m.pt

# YOLOv11 (New SOTA)
python3 examples/basic_detection.py --model yolo11n.pt

# RT-DETR (Transformer)
python3 examples/basic_detection.py --model rtdetr-l.pt
```

### Multi-Camera (Stereo/Array)
Support for synchronized processing of multiple camera streams:
```bash
python3 examples/multi_camera_detection.py --cameras 0 1
```

## âš¡ Performance

To unlock full performance on Jetson:

1.  **Maximize Clocks:** `sudo nvpmodel -m 0 && sudo jetson_clocks`
2.  **Use TensorRT:**
    ```bash
    # Convert any model
    python3 examples/tensorrt_export.py --model yolo11n.pt --export
    
    # Run optimized model
    python3 examples/basic_detection.py --model yolo11n.engine
    ```

## ğŸ¤ Support
Open an issue for bugs or feature requests. See [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) for help.

## License
MIT License.
